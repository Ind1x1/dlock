apiVersion: elastic.iml.github.io/v1alpha1
kind: ElasticJob
metadata:
  name: fine-tuning-llama2
  namespace: dlock
spec:
  distributionStrategy: AllreduceStrategy
  optimizeMode: single-job
  replicaSpecs:
    worker:
      replicas: 2
      template:
        spec:
          restartPolicy: Never
          volumes:
            - name: dlock-volume
              persistentVolumeClaim:
                claimName: dlock-nas-pvc 
            - name: dlock-shm 
              emptyDir:
                medium: Memory
                sizeLimit: 50Gi 
          containers:
            - name: main
              image: llama:latest
              imagePullPolicy: Never
              command:
                - /bin/bash
                - -c
                - "dlock-run --nnodes=$NODE_NUM \
                  --nproc_per_node=1 --max_restarts=1 \
                  ./examples/llama3/deepspeed_test.py"
              resources:
                limits:
                  cpu: "8"
                  memory: 16Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: "4"
                  memory: 16Gi
                  nvidia.com/gpu: 1
              volumeMounts:
                - mountPath: "/dlock/examples/output"
                  name: dlock-volume
                - mountPath: "/dev/shm" 
                  name: dlock-shm
